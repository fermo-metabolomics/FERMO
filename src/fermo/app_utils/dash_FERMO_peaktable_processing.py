import pandas as pd
import numpy as np
import matchms
from matchms.Spectrum import Spectrum
import os
from datetime import datetime

from fermo.processing.read_from_metadata_table import (
    read_from_metadata_table
)
from fermo.processing.collect_stats_samples import (
    collect_stats_samples
)
from fermo.processing.get_samplespecific_features import (
    get_samplespecific_features
)
from fermo.processing.set_from_sample_tables import (
    set_from_sample_tables
)
from fermo.processing.feature_dicts_creation import (
    feature_dicts_creation
)
from fermo.processing.determine_blank_features import (
    determine_blank_features
)
from fermo.processing.determine_bioactive_features import (
    determine_bioactive_features
)
from fermo.processing.calculate_similarity_cliques import (
    calculate_similarity_cliques
)
from fermo.processing.library_search import (
    library_search
)
from fermo.processing.ms2query_search import (
    ms2query_search
)
from fermo.processing.calculate_feature_overlap import (
    calculate_feature_overlap
)
from fermo.processing.calculate_metrics import (
    calculate_metrics
)
from fermo.processing.calculate_pseudochrom_traces import (
    calculate_pseudochrom_traces
)
from fermo.processing.determine_trend_bioactivity import (
    determine_trend_bioactivity
)


def prepare_spectral_library(
    userlib_dict,
):
    '''Prepare spectral library using matchMS

    Parameters
    ----------
    userlib_dict : `dict`

    Returns
    --------
    ref_library : `list`
    '''
    ref_library = list()

    for i in userlib_dict:
        mz = np.array(userlib_dict[i][0], dtype=float)
        intensities = np.array(userlib_dict[i][1], dtype=float)
        metadata_ms2 = userlib_dict[i][2]

        if not np.all(mz[:-1] <= mz[1:]):
            idx_sorted = np.argsort(mz)
            mz = mz[idx_sorted]
            intensities = intensities[idx_sorted]

        ref_library.append(
            Spectrum(
                mz=mz,
                intensities=intensities,
                metadata=metadata_ms2,
            )
        )

    ref_library = [
        matchms.filtering.add_compound_name(s) for s in ref_library
    ]
    ref_library = [
        matchms.filtering.normalize_intensities(s) for s in ref_library
    ]
    ref_library = [
        matchms.filtering.select_by_intensity(s, intensity_from=0.01)
        for s in ref_library
    ]
    ref_library = [
        matchms.filtering.add_precursor_mz(s) for s in ref_library
    ]
    ref_library = [
        matchms.filtering.require_precursor_mz(s) for s in ref_library
    ]

    return ref_library


def write_process_log(
    log_dict,
    counter,
    message,
):
    '''Writes process log into dict

    Parameters
    ----------
    log_dict : `dict`
    counter : `int`
    message : `str`

    Returns
    -------
    log_dict : `dict`
    counter : `int`

    Notes
    -----
    Prints logging messages to standard output too, good for users
    to see that something changes; can be later changed
    '''
    print(message)

    log_dict[counter] = message
    counter = counter + 1
    return log_dict, counter


def peaktable_processing(
    uploaded_files_store,
    dict_params,
):
    """FERMO: peaktable processing

    Parameters
    ----------
    uploaded_files_store : `dict`
        contains parsed user-provided input data
    dict_params : `dict`
        contains user-provided parameters

    Returns
    --------
    FERMO_data : `dict`
        contains data to feed into dashboard visualization
    """
    log_dict = dict()
    ms2_dict = dict()
    counter = 0
    peaktable = None
    metadata = None
    bioactivity = None
    orig_bioactiv = None
    ref_library = None

    peaktable = pd.read_json(
        uploaded_files_store['peaktable'],
        orient='split',
    )

    mgf = uploaded_files_store['mgf']
    for ID in mgf:
        ms2_dict[int(ID)] = [
            np.array(mgf[ID][0], dtype=float),
            np.array(mgf[ID][1], dtype=float),
        ]

    if uploaded_files_store['metadata_name'] is not None:
        metadata = pd.read_json(
            uploaded_files_store['metadata'],
            orient='split',
        )

    if uploaded_files_store['bioactivity_name'] is not None:
        bioactivity = pd.read_json(
            uploaded_files_store['bioactivity'],
            orient='split',
        )
        orig_bioactiv = pd.read_json(
            uploaded_files_store['bioactivity_original'],
            orient='split',
        )

    if uploaded_files_store['user_library_name'] is not None:
        ref_library = prepare_spectral_library(
            uploaded_files_store['user_library_dict']
        )

    # BEGIN PROCESSING

    groups = read_from_metadata_table(
        metadata,
        uploaded_files_store['metadata_name'],
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "read_from_metadata_table.py"'
        ])
    )

    sample_stats = collect_stats_samples(
        peaktable,
        groups,
        bioactivity,
        orig_bioactiv,
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "collect_stats_samples.py"'
        ])
    )

    samples = get_samplespecific_features(
        peaktable,
        sample_stats,
        dict_params['relative_intensity_filter_range'],
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "get_samplespecific_features.py":
            Relative intensity range filter :
            {dict_params['relative_intensity_filter_range']};'''
        ])
    )

    detected_features = set_from_sample_tables(samples)
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "set_from_sample_tables.py"'
        ])
    )

    feature_dicts = feature_dicts_creation(
        peaktable,
        ms2_dict,
        dict_params['min_nr_ms2'],
        sample_stats,
        detected_features
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "feature_dicts_creation.py": Min nr of
            fragments per MSÂ² spectrum :
            {dict_params['min_nr_ms2']};'''
        ])
    )

    feature_dicts = determine_blank_features(
        samples,
        feature_dicts,
        dict_params['column_ret_fact'],
        sample_stats,
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "determine_blank_features.py": Blank factor :
            {dict_params['column_ret_fact']};'''
        ])
    )

    feature_dicts = determine_bioactive_features(
        bioactivity,
        samples,
        feature_dicts,
        dict_params['bioact_fact'],
        sample_stats,
        uploaded_files_store['bioactivity_name'],
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "determine_bioactive_features.py":
            QuantData factor : {dict_params['bioact_fact']};'''
        ])
    )

    spec_sim_net_alg_used, feature_dicts = calculate_similarity_cliques(
        feature_dicts,
        sample_stats,
        dict_params['spectral_sim_tol'],
        dict_params['spec_sim_score_cutoff'],
        dict_params['max_nr_links_ss'],
        dict_params['spec_sim_net_alg'],
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "calculate_similarity_cliques.py":
            Fragment similarity tolerance :
            {dict_params['spectral_sim_tol']};
            Spectrum similarity score cutoff :
            {dict_params['spec_sim_score_cutoff']};
            Max spectral links :
            {dict_params['max_nr_links_ss']};
            Spectral similarity algorithm used:
            {dict_params['spec_sim_net_alg']}'''
        ])
    )

    if uploaded_files_store['user_library_name']:
        feature_dicts = library_search(
            feature_dicts,
            ref_library,
            dict_params['spectral_sim_tol'],
            dict_params['spec_sim_score_cutoff'],
            dict_params['min_nr_matched_peaks'],
        )
        log_dict, counter = write_process_log(
            log_dict,
            counter,
            ': '.join([
                str(datetime.now()),
                f'''Completed: "library_search.py": Fragment similarity
                tolerance : {dict_params['spectral_sim_tol']};
                Spectrum similarity score cutoff :
                {dict_params['spec_sim_score_cutoff']};
                Min matched peaks :
                {dict_params['min_nr_matched_peaks']};'''
            ])
        )

    if dict_params['ms2query']:
        input_folder = os.path.join(
            os.path.dirname(os.path.dirname(__file__)),
            'libraries',
        )
        if os.path.exists(input_folder):
            feature_dicts = ms2query_search(
                feature_dicts,
                input_folder,
                dict_params['ms2query_blank_annotation'],
                dict_params['ms2query_filter_range'],
                samples,
                sample_stats,
            )
            log_dict, counter = write_process_log(
                log_dict,
                counter,
                ': '.join([
                    str(datetime.now()),
                    f'''Completed: "ms2query_search.py":
                    MS2Query blank annotation :
                    {dict_params['ms2query_blank_annotation']};
                    relative intensity filter:
                    {dict_params['ms2query_filter_range']};'''
                ])
            )

    samples, feature_dicts = calculate_feature_overlap(
        samples,
        dict_params['mass_dev_ppm'],
        feature_dicts,
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            f'''Completed: "calculate_feature_overlap.py":
            Fragment similarity tolerance :
            {dict_params['mass_dev_ppm']};'''
        ])
    )

    samples, feature_dicts = calculate_metrics(
        samples,
        feature_dicts,
        sample_stats,
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "calculate_metrics.py"'
        ])
    )

    feature_dicts = determine_trend_bioactivity(feature_dicts, sample_stats)
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "determine_trend_bioactivity.py"'
        ])
    )

    samples = calculate_pseudochrom_traces(
        samples,
    )
    log_dict, counter = write_process_log(
        log_dict,
        counter,
        ': '.join([
            str(datetime.now()),
            'Completed: "calculate_pseudochrom_traces.py"'
        ])
    )

    for sample in samples:
        samples[sample].sort_values(
            by=['norm_intensity',],
            inplace=True,
            ascending=[False]
        )
        samples[sample].reset_index(drop=True, inplace=True)

    input_filenames = {
        'peaktable_name': uploaded_files_store['peaktable_name'],
        'mgf_name': uploaded_files_store['mgf_name'],
        'metadata_name': uploaded_files_store['metadata_name'],
        'bioactivity_name': uploaded_files_store['bioactivity_name'],
        'user_library_name': uploaded_files_store['user_library_name'],
    }

    FERMO_data = {
        'feature_dicts': feature_dicts,
        'samples': samples,
        'sample_stats': sample_stats,
        'params_dict': dict_params,
        'input_filenames': input_filenames,
        'log_dict': log_dict,
    }

    return FERMO_data


def make_JSON_serializable(
    FERMO_data,
    FERMO_version,
):
    """Make JSON compatible by removing non-base python data structures

    Parameters
    ----------
    FERMO_data : `dict`
    FERMO_version : `str`

    Returns
    --------
    storage_JSON_dict : `dict`

    Notes
    -----
    loop over feature_dicts to prepare for storage
    convert all sets to lists
    remove matchms Spectrum object
    loop over sample stats to replace sets with lists
    """
    samples_JSON = dict()
    for sample in FERMO_data['samples']:
        samples_JSON[sample] = FERMO_data['samples'][sample].to_json(
            orient='split'
        )

    for ID in FERMO_data['feature_dicts']:
        for entry in FERMO_data['feature_dicts'][ID]:
            if isinstance(FERMO_data['feature_dicts'][ID][entry], set):
                set_to_list = list(FERMO_data['feature_dicts'][ID][entry])
                FERMO_data['feature_dicts'][ID][entry] = set_to_list

            FERMO_data['feature_dicts'][ID]['ms2spectrum'] = 'removed'

    for entry in FERMO_data['sample_stats']:
        if isinstance(FERMO_data['sample_stats'][entry], set):
            set_to_list = list(FERMO_data['sample_stats'][entry])
            FERMO_data['sample_stats'][entry] = set_to_list

    for group in FERMO_data['sample_stats']['groups_dict']:
        set_to_list = list(FERMO_data['sample_stats']['groups_dict'][group])
        FERMO_data['sample_stats']['groups_dict'][group] = set_to_list

    session_metadata = {
        'date': str(datetime.date(datetime.now())),
        'time': str(datetime.time(datetime.now())),
    }

    storage_JSON_dict = {
        'feature_dicts': FERMO_data['feature_dicts'],
        'samples_JSON': samples_JSON,
        'sample_stats': FERMO_data['sample_stats'],
        'params_dict': FERMO_data['params_dict'],
        'input_filenames': FERMO_data['input_filenames'],
        'session_metadata': session_metadata,
        'FERMO_version': FERMO_version,
        'logging_dict': FERMO_data['log_dict'],
    }

    return storage_JSON_dict
